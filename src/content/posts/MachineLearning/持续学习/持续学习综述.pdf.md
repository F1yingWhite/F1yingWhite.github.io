---
title: 持续学习综述
description: ""
image: ""
published: 2025-03-01
tags:
  - 论文阅读
category: 论文阅读
draft: false
path: "[[MachineLearning/持续学习/持续学习综述.pdf|持续学习综述]]"
---

关键词：后训练 持续学习 开放世界 多模态学习

# 前言

为了应对真实世界的变化，一个优秀的模型应该能够增量的获取，更新并利用知识。这种能力被称为**持续学习**（continual learning），它为人工智能系统实现自适应发展提供了基础。从广义上讲，持续学习的主要障碍是**灾难性遗忘**（catastrophic forgetting），即学习新任务通常会导致模型在旧任务上的性能显著下降。在目前的实验下，我们将持续学习的目标总结为：实现适当的稳定性 - 可塑性权衡以及充分利用任务内与任务间的泛化能力。持续学习也被叫做终身学习或者增量学习

与传统的机器学习在静态的数据分布假设不同，持续学习的核心在于**如何在动态的数据分布**中进行学习。其中最重要的问题就是灾难性遗忘，也就是模型在适应新数据的分布时候会忘记老数据的分布。这一困境体现了“学习可塑性”与“记忆稳定性”之间的权衡：过度强调前者会干扰后者，反之亦然。通常来说使用所有旧的训练数据能解决上述问题，但是需要的资源开销太大。实际上持续学习的主要目的是**确保模型更新的资源效率，理想情况下应接近仅对新训练样本进行学习即可完成更新。**

当前的 CL 算法可以分为 5 大类：回放，架构，表示，正则化以及优化。

1. **基于正则化的方法**：通过参考旧模型添加正则化项；
2. **基于回放的方法**：近似和恢复旧数据分布；
3. **基于优化的方法**：显式地操纵优化程序；
4. **基于表示的方法**：学习鲁棒且分布良好的表示；
5. **基于架构的方法**：通过精心设计的架构构建任务自适应参数。

## 灾难性遗忘

从“哲学”上来说，假设模型的学习能力是固定的，模型在新任务上效果好，则在旧任务上效果会变差；反之，模型保持了旧任务上的效果，则在新任务上效果就不会好。前者是模型学习新知识的能力，称为**可塑性**（plasticity）；后者是旧知识的记忆能力，称为**稳定性**（stability）。可塑性与稳定性是内在相互矛盾的，术语叫**可塑性 - 稳定性困境**（Stability-Plasticity Dilemma），这是机器学习的一个天然的哲学约束，类似于 “没有免费午餐定理”。持续学习的目标是在所有任务上表现都好，即同时追求可塑性和稳定性；但这个困境说明了实现这一目标没有捷径，持续学习场景不是伪命题，并不是无脑加防遗忘机制、加强防遗忘的力度（例如调大防遗忘正则项超参数）就可以了，必须切实地提高模型的真本领。

除了灾难性遗忘作为核心问题，持续学习还关心算法是否具备：

- **后向迁移**（backward transfer）能力：学习后面的任务时，能否帮助到前面的任务；
- **前向迁移**（forward transfer）能力：学习前面的任务时，能否帮助到后面的任务。
拥有后向迁移能力是比克服灾难性遗忘还要厉害的事情。克服灾难性遗忘仅仅是学习后面的任务不会给前面的任务帮倒忙，而后向迁移还要求能帮正忙。按照我的理解，后向迁移能力与灾难性遗忘是同一种能力的两种程度。

拥有前向迁移能力意味着，在还没有见到要学习的任务时，就已经在积累该任务的知识，并且在训练该任务时用到。由于没有该任务的信息，这种能力也是最难拥有的，目前持续学习的研究基本无法触碰这个话题。

## 模型容量分配问题

持续学习的一大特点是学习任务的类型和数量没有预定义。在学习每个任务的期间，永远不知道未来有多少个任务、它们是什么样子的。我们不希望模型大小无序地膨胀，而是**固定模型容量**（capacity），让算法在固定容量的模型下完成持续学习（偶尔也会允许少量的膨胀）。

很显然，固定容量的模型，随着任务越来越多，模型也不能容纳所有的知识，会出现**模型容量饱和**（capacity saturation）问题。知识必须有所舍弃，各任务上的效果也会打折扣，遗忘也就越严重。由于深度学习基于的是参数化的神经网络模型，这个问题是不可能解决的，因为参数是会被覆写的，模型的表示能力是有限的。目前持续学习的研究致力于**缓解这个问题，而不是彻底解决它**。一个好的持续学习算法能让模型尽量记住任务重要的知识，在需要舍弃知识时舍弃不重要的，减少模型表示上的重叠或冗余，从而减缓遗忘的速度。

在学习中，每个任务都会占据一定的容量，任务间也会占用部分容量，因此我们需要在算法中加入稀疏化来解决模型容量不足的问题。

# 学习曲线

在训练过程中我们需要对学习曲线进行监视，持续学习有多个任务，就有多个独立的学习曲线，我们更关注是否会出现灾难性遗忘，所以需要监视模型在旧任务上的表现。

![image.png](https://picture-bed-1325530970.cos.ap-nanjing.myqcloud.com/20250816133124522.png)

# 设定

## 基本公式

持续学习被认为是从动态的数据分布中进行学习，在实际中，不同分布的训练样本按批次抵达，一个模型 $\theta$ 需要在对旧数据有限的接触的情况下学习对应的任务 $s$ 并且在测试集上表现良好,属于任务 $t$ 的一组样本表示为 $\mathcal{D}_{t,b}=\{\mathcal{X}_{t,b}.\mathcal{Y}_{t,b}\}$，其中 x 是输入数据，y 是对应的标签，$t \in \mathcal{T} = \{1, \cdots, k\}$ 是任务标识，$b \in \mathcal{B}_t$ 是批次索引。每个任务 $t$ 的样本都服从分布 $\mathbb{D}_{t}:=p(\mathcal{X}_{t},\mathcal{Y}_{t})$，并且训练和测试的分布没有区别。但是通常标签和任务标识并非总是可用，每个任务的 batch 能够按批次到达也可以同时到达。

## 评判标准

通常可以从三个方面来评估持续学习的效果：**迄今为止所学任务的整体性能、旧任务的记忆稳定性以及新任务的学习可塑性。**

### Overall Performance

通常使用 average accuracy 和 average incremental accuracy 来评估总体性能。令 $a_{k,j}$ 是在训练了 k 个任务后的第 j 个任务上的分类准确率，指标如下：

$$
\text{AA}_k = \frac{1}{k} \sum_{j=1}^{k} a_{k,j}
$$

$$
\text{AIA}_k = \frac{1}{k} \sum_{i=1}^{k} \text{AA}_i
$$

这里的 AA 表示当前的总体准确率，AIA 更多的反应了历史准确率

### Memory Stability

记忆稳定性可以通过遗忘度量（forgetting measure）和向后迁移 (backward transfer) 来评估

对于前者，对任务的遗忘可以通过以往最大性能和现在的性能来计算

$$
f_{j,k} = \max_{i \in \{1, \ldots, k-1\}} (a_{i,j} - a_{k,j}), \quad \forall j < k. \tag{3}
$$

在第 $k$ 个任务时，FM 是所有旧任务平均遗忘程度：

$$
\text{FM}_k = \frac{1}{k - 1} \sum_{j=1}^{k-1} f_{j,k}. \tag{4}
$$

于后者，BWT 评估学习第 $k$ 个任务对所有旧任务的平均影响：

$$
\text{BWT}_k = \frac{1}{k - 1} \sum_{j=1}^{k-1} (a_{k,j} - a_{j,j}), \tag{5}
$$

其中，遗忘通常表现为负的 BWT 值。

### Learning Plasticity

学习可塑性能通过不可转移性度量（Intransience Measure, IM）] 和向前迁移（Forward Transfer, FWT）来评估。

IM 被定义为模型学习新任务能力的不足，通过某一任务在联合训练性能与持续学习性能之间的差异来计算：

$$
\text{IM}_k = a_k^* - a_{k,k}
$$

这里的其中 $a_k^*$ 是一个随机初始化的参考模型在联合训练所有前 $k$ 个任务数据 $\bigcup_{j=1}^k D_j$ 后，在第 $k$ 个任务上的分类准确率。相比之下，FWT 评估所有旧任务对当前第 $k$ 个任务的平均影响：

$$
\text{FWT}_k = \frac{1}{k - 1} \sum_{j=2}^{k} (a_{j,j} - \bar{a}_j), \tag{7}
$$

其中 $\bar{a}_j$ 是一个随机初始化的参考模型仅使用第 $j$ 个任务的数据 $D_j$ 进行训练后在该任务上的分类准确率。

需要注意的是，$a_{k,j}$ 可以根据任务类型调整为其他形式，例如目标检测中的平均精度（AP）、语义分割中的交并比（IoU）、图像生成中的弗雷赫特 inception 距离（FID）、强化学习中的归一化奖励 等，上述评估指标也应相应地进行调整。

# 理论基础

现在有一个网络 $\theta$ 需要学习 $k$ 个增量任务，每个任务的训练集和训练集有同样的分布 $\mathbb{D}_{t}$,目标是学习一个模型分布 $$p(\mathcal{D}_{1:k}|\theta) = \prod_{t=1}^k p(\mathcal{D}_t|\theta)$$

在连续学习中，旧的训练集是无法被访问的，因此，同时平衡的捕捉新老数据集的分布很重要但是具有挑战。

一个直观的想法是通过存储少量旧的训练样本或训练一个生成模型来近似并恢复旧数据的分布，这种方法叫做基于回放的方法，通过重放更多能够近似其分布的旧训练样本，可以提升对旧任务的性能，但这种方法可能带来潜在的隐私问题，并导致资源开销呈线性增长。此外，使用生成模型也受到巨大额外资源开销的限制，同时它们自身还存在灾难性遗忘和表达能力不足的问题。

另一种选择是在贝叶斯框架下，通过在更新参数时传播旧数据分布来构建连续学习，基于网络参数的先验 $p(\theta)$，在观测到第 $k$ 个任务后，其后验概率可通过贝叶斯规则计算：

$$
p(\theta|\mathcal{D}_{1:k}) \propto p(\theta) \prod_{t=1}^k p(\mathcal{D}_t|\theta) \propto p(\theta|\mathcal{D}_{1:k-1}) p(\mathcal{D}_k|\theta)\tag{8}
$$

其中，第 $(k-1)$ 个任务的后验 $p(\theta|\mathcal{D}_{1:k-1})$ 成为第 $k$ 个任务的先验，从而使得新的后验 $p(\theta|\mathcal{D}_{1:k})$ 可以仅利用当前训练集 $\mathcal{D}_k$ 进行计算。然而，由于后验通常难以解析求解（除了一些非常特殊的情况），一种常见做法是用 $q_{k-1}(\theta) \approx p(\theta|\mathcal{D}_{1:k-1})$ 来近似它，类似地，$q_k(\theta) \approx p(\theta|\mathcal{D}_{1:k})$。

第一种策略是在线拉普拉斯近似，使用局部梯度信息将 $p(\theta|\mathcal{D}_{1:k-1})$ 近似为多元高斯分布，具体来说，我们可以用参数 $\phi_{k-1} = \{\mu_{k-1}, \Lambda_{k-1}\}$ 来参数化近似后验 $q_{k-1}(\theta)$，并构造一个近似的高斯后验：

$$
q_{k-1}(\theta) := q(\theta; \phi_{k-1}) = \mathcal{N}(\theta; \mu_{k-1}, \Lambda_{k-1}^{-1})
$$

这可以通过在 $p(\theta|\mathcal{D}_{1:k-1})$ 的众数点 $\mu_{k-1} \in \mathbb{R}^{|\theta|}$ 附近进行二阶泰勒展开实现，其中 $\Lambda_{k-1}$ 表示精度矩阵（precision matrix），$\phi_k = \{\mu_k, \Lambda_k\}$ .

根据公式 (8)，学习当前第 $k$ 个任务的后验众数可以计算为：

$$
\begin{aligned}
\mu_k &= \arg\max_\theta \log p(\theta|D_{1:k}) \\
&\approx \arg\max_\theta \log p(D_k|\theta) + \log q(\theta; \phi_{k-1}) \\
&= \arg\max_\theta \log p(D_k|\theta) - \frac{1}{2}(\theta - \mu_{k-1})^\top \Lambda_{k-1} (\theta - \mu_{k-1}),
\end{aligned}
\tag{9}
$$

该结果从 $\mu_{k-1}$ 和 $\Lambda_{k-1}$ 递归更新得到。同时，$\Lambda_k$ 也从 $\Lambda_{k-1}$ 递归更新：

$$
\begin{aligned}
\Lambda_k &= -\nabla_\theta^2 \log p(\theta|D_{1:k})\big|_{\theta=\mu_k} \\
&\approx -\nabla_\theta^2 \log p(D_k|\theta)\big|_{\theta=\mu_k} + \Lambda_{k-1},
\end{aligned}
\tag{10}
$$
