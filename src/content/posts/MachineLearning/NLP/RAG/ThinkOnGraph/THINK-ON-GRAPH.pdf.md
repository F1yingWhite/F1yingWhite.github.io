---
title: "[[MachineLearning/NLP/RAG/ThinkOnGraph/THINK-ON-GRAPH.pdf|THINK-ON-GRAPH]]"
description: ""
image: ""
published: 2025-03-07
tags:
  - 论文阅读
category: 论文阅读
draft: false
---

>[!summary]
>这篇文章采用了大模型自动推断的方式，让大模型自己选择下一条的路径并打分，得到一条从查询实习到答案实体的连续的道路，从而得到最终的结果。在模型递归深度达到 n 的时候如果仍然没有查询到相关信息，那么模型停止查询并使用内置的知识进行问答，防止来自知识图谱的信息污染回复。

我们的方法让 llm 想 agent 一样不断的在知识图谱上进行搜索，找到最相关的路径。ToG 具有知识可追溯性和知识可纠正性。即插即用。在我们的范式中，llm 冲当翻译者的角色，把输入的问题转换为机器可理解的指令，提供 kg 搜索和推理，但是他在很大程度上取决于 kg 的完整性和高质量。

TOG 能够自主判断推理路径的条数。<span style="background:#ff4d4f">他让 llm 自主迭代的推断需要多少条路径直到 llm 认为当前的路径足够推理出</span>。TOG 每次保持前 k 个最可能的推理路径，总的来说，推理步骤有 3 个阶段：初始化，探索和归因

# 具体步骤

## 初始化

给定一个问题，llm 会对问题的起点实体进行初始化，llm 会从问题中提取 topk 个实体

## 探索

在第 d 个迭代的开始，每个路径包含 d-1 个三元组 $p_n=\{(e_{s,n}^d,r_{j,n}^d,e_{o,n}^d)\}_{d=1}^{D-1},$，并且前一个和后一个三元组是连续的。

探索阶段希望 llm 根据前 n 个实体的临近实体探索出最相关的 N 个实体，并且扩展这些路径。然后进行剪枝，减去不相关的路径。

## 归因

在获得了这些原因后，我们 prompt llm 来判断当前的信息是否足够生成答案。如果不够就重复探索阶段。如果深度达到最大但是探索仍然没有结束，那么 ToG 将完全根据 llm 中的固有只是回答问题。最多需要 ND+D+1 次 llm 调用

# 实验细节

为了测试 ToG 在只是图谱密集推理任务的性能，我们测试了 KBQA(4-hop and 1 hop)，CWQ，WebQSP，GrailQA，QALD10-en，Simple Questions。为了验证更为番用的性能，我们还准备了开放领域的问答:WebQuestions,Creak。对于所有数据集，我们都采用精确匹配准确率来作为评估指标

我们比较了标准 prompt，CoT，和 self Consistency,进行比较并且在每个数据集上都使用了以往的 SOTA 进行比对。

在试验中，我们测试了三种 llm,分别是 api 调用的 chatgpt，gpt-4 和 llama2-70B，其中探索过程设置为 0.4(保证多样性)，推理过程的温度设置为 0 为了保证可重复性。

在试验中我们还发现采用三元组形式的模型能够达到最好的性能。我们还测试了不同剪枝工具的影响。比如 BM25 和 sentenceBERT 用来充当剪枝工具，但是发现效果明显降低，作为剪枝工具，llm 的效果最好了

## 知识可追溯性与可纠正性

知识库的质量对了；llm 非常重要，TOG 提供了一种利用 ToG 本身来提升 KG 质量和降低 KG 成本的方法。如果专家发现推理路径中存在错误，那么能够追溯并且更正他们。
